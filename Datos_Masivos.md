___

# **Datos Masivos.**

Big data, macrodatos, datos masivos, inteligencia de datos o datos a gran escala es un concepto que hace referencia a un conjuntos de datos tan grandes que aplicaciones informáticas tradicionales de procesamiento de datos no son suficientes para tratar con ellos y los procedimientos usados para encontrar patrones repetitivos dentro de esos datos. Los textos científicos en español con frecuencia se usa directamente el término en inglés big data, tal como aparece en el ensayo de Viktor Schönberger: La revolución de los datos masivos.​

La disciplina dedicada a los datos masivos se enmarca en el sector de las tecnologías de la información y la comunicación. Esta disciplina se ocupa de todas las actividades relacionadas con los sistemas que manipulan grandes conjuntos de datos. Las dificultades más habituales vinculadas a la gestión de estas cantidades de datos se centran en la recolección y el almacenamiento, búsqueda, compartición, análisis, y visualización. La tendencia a manipular enormes cantidades de datos se debe a la necesidad en muchos casos de incluir dicha información para la creación de informes estadísticos y modelos predictivos utilizados en diversas materias, como los análisis de negocio, publicitarios, los datos de enfermedades infecciosas, el espionaje y seguimiento a la población o la lucha contra el crimen organizado.

El límite superior de procesamiento ha ido creciendo a lo largo de los años. Se estima que el mundo almacenó unos 5 zettabytes en 2014. Si se pone esta información en libros, convirtiendo las imágenes y todo eso a su equivalente en letras, se podría hacer 4500 pilas de libros que lleguen hasta el sol. Los científicos con cierta regularidad encuentran límites en el análisis debido a la gran cantidad de datos en ciertas áreas, tales como la meteorología, la genómica, la conectómica, las complejas simulaciones de procesos físicos​ y las investigaciones relacionadas con los procesos biológicos y ambientales,​ Las limitaciones también afectan a los motores de búsqueda en internet, a los sistemas finanzas y a la informática de negocios. Los data sets crecen en volumen debido en parte a la recolección masiva de información procedente de los sensores inalámbricos y los dispositivos móviles (por ejemplo las VANET), el constante crecimiento de los históricos de aplicaciones (por ejemplo de los registros), cámaras (sistemas de teledetección), micrófonos, lectores de identificación por radiofrecuencia. La capacidad tecnológica per cápita a nivel mundial para almacenar datos se dobla aproximadamente cada cuarenta meses desde los años 1980.​ Se estima que en 2012 cada día fueron creados cerca de 2.5 trillones de bytes de datos.

## **Definición.**

Big data o macrodatos es un término que hace referencia a una cantidad de datos tal que supera la capacidad del software convencional para ser capturados, administrados y procesados en un tiempo razonable. El volumen de los datos masivos crece constantemente. En 2012 se estimaba su tamaño de entre una docena de terabytes hasta varios petabytes de datos en un único conjunto de datos. En la metodología MIKE2.0 dedicada a investigar temas relacionados con la gestión de información, definen big data​ en términos de permutaciones útiles, complejidad y dificultad para borrar registros individuales.

Se ha definido también como datos lo suficientemente masivos como para poner de relieve cuestiones y preocupaciones en torno a la efectividad del anonimato desde una perspectiva más práctica que teórica.​

En 2001, en un informe de investigación que se fundamentaba en congresos y presentaciones relacionadas, la META Group (ahora Gartner) definía el crecimiento constante de datos como una oportunidad y un reto para investigar en el volumen, la velocidad y la variedad. Gartner' continúa usando datos masivos como referencia.​ Además, grandes proveedores del mercado de datos masivos están desarrollando soluciones para atender las demandas más críticas sobre cómo procesar tal cantidad de datos, como MapR y Cloudera.

## **Características.**

Los macrodatos se pueden describir por las siguientes características:

* Volumen: la cantidad de datos generados y guardado. El tamaño de los datos determina el valor y entendimiento potencial, y si los puede considerar como auténticos macrodatos.

* Variedad: el tipo y naturaleza de los datos para ayudar a las personas a analizar los datos y usar los resultados de forma eficaz. Los macrodatos usan textos imágenes, audio y vídeo. También completan pedazos pedidos a través de la fusión de datos.

* Velocidad: en este contexto, la velocidad a la cual se generan y procesan los datos para cumplir las exigencias y desafíos de su análisis.

* Veracidad: la calidad de los datos capturados puede variar mucho y así afectar a los resultados del análisis.

## **Tecnología.**

Existen muchísimas herramientas para tratar con big data. Algunos ejemplos incluyen Hadoop, NoSQL, Cassandra, inteligencia empresarial, aprendizaje automático y MapReduce. Estas herramientas tratan con algunos de los tres tipos de big data:

* Datos estructurados: datos que tienen bien definidos su longitud y su formato, como las fechas, los números o las cadenas de caracteres. Se almacenan en tablas. Un ejemplo son las bases de datos relacionales y los almacenes de datos.

* Datos no estructurados: datos en el formato tal y como fueron recolectados, carecen de un formato específico. No se pueden almacenar dentro de una tabla ya que no se puede desgranar su información a tipos básicos de datos. Algunos ejemplos son los PDF, documentos multimedia, correos electrónicos o documentos de texto.

* Datos semiestructurados: datos que no se limitan a campos determinados, pero que contiene marcadores para separar los diferentes elementos. Es una información poco regular como para ser gestionada de una forma estándar. Estos datos poseen sus propios metadatos semiestructurados20​ que describen los objetos y las relaciones entre ellos, y pueden acabar siendo aceptados por convención. Como ejemplos tenemos los archivos tipo hojas de cálculo, HTML, XML o JSON.

### **Captura.**

¿De dónde provienen todos estos datos? Los fabricamos directa e indirectamente segundo tras segundo. Un iPhone hoy en día tiene más capacidad de cómputo que la NASA cuando el hombre llegó a la luna21​ por lo que la cantidad de datos generados por persona y en unidad de tiempo es muy grande. Catalogamos la procedencia de los datos según las siguientes categorías:22​

Generados por las personas, Transacciones de datos, Marketing electrónico y web, Máquina a máquina, Biométrica.

### **Análisis De Datos.**

Teniendo los datos necesarios almacenados según diferentes tecnologías de almacenamiento, nos daremos cuenta que necesitaremos diferentes técnicas de análisis de datos como las siguientes.

* Asociación: permite encontrar relaciones entre diferentes variables.​ Bajo la premisa de causalidad, se pretende encontrar una predicción en el comportamiento de otras variables. Estas relaciones pueden ser los sistemas de ventas cruzadas en los comercios electrónicos.

* Minería de datos (data mining): tiene como objetivo encontrar comportamientos predictivos. Engloba el conjunto de técnicas que combina métodos estadísticos y de aprendizaje automático con almacenamiento en bases de datos.​ Está estrechamente relacionada con los modelos utilizados para descubrir patrones en grandes cantidades de datos.

* Agrupación (clustering): el análisis de clústeres es un tipo de minería de datos que divide grandes grupos de individuos en grupos más pequeños de los cuales no conocíamos su parecido antes del análisis.31​ El propósito es encontrar similitudes entre estos grupos, y el descubrimiento de nuevos, conociendo cuáles son las cualidades que lo definen. Es una metodología apropiada para encontrar relaciones entre resultados y hacer una evaluación preliminar de la estructura de los datos analizados. Existen diferentes técnicas y algoritmos de clusterización.

* Análisis de texto (text analytics): gran parte de los datos generados por las personas son textos, como correos, búsquedas web o contenidos. Esta metodología permite extraer información de estos datos y así modelar temas y asuntos o predecir palabras.

## **Utilidad.**

Este conjunto de tecnologías se puede usar en una gran variedad de ámbitos, como los siguientes.

Democracia, Empresas, Deportes, Investigación,...

## **Virtualización De Big Data.**

La virtualización de big data es una forma de recopilar información de múltiples fuentes en el mismo lugar. El ensamblaje es virtual: a diferencia de otros métodos, la mayoría de los datos permanecen en su lugar y se toman bajo demanda directamente desde el sistema de origen.

---
